{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb8b6feb-4b77-481f-a7f9-83599549646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch120/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric as pyg\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from utils import load_pickle\n",
    "from models import GraphFloorplanUNet\n",
    "import cv2\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3534312a-a01f-4df4-83ab-667ab3b2920f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analysis_array(array):\n",
    "\n",
    "    # Flatten the array\n",
    "    flattened_arr = array.flatten()\n",
    "\n",
    "    # Find unique elements\n",
    "    unique_elements = np.unique(flattened_arr)\n",
    "\n",
    "    return unique_elements, len(unique_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21864081-577f-4eb9-acc9-750f4a23730b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_result(boundary_image_np, gt_image_np, predicted_np):\n",
    "    colors = ['#1f77b4','#e6550d','#fd8d3c','#87ceeb','#ffff00','#72246c','#5254a3','#6b6ecf','#2ca02c','#000000','white']\n",
    "    cmap = ListedColormap(colors)\n",
    "    \n",
    "    # Plot the boundary image, prediction, and ground truth\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axs[0].imshow(boundary_image_np, cmap='gray')\n",
    "    # axs[0].set_title('Boundary Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    predicted_np[predicted_np == 13] = 10\n",
    "    axs[1].imshow(predicted_np, cmap=cmap)\n",
    "    # axs[1].set_title('Prediction')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    gt_image_np[gt_image_np == 13] = 10\n",
    "    im = axs[2].imshow(gt_image_np, cmap=cmap)\n",
    "    # axs[2].set_title('Ground Truth')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    # Create legend\n",
    "    legend_labels = {\n",
    "        'Bedroom': 0,\n",
    "        'Livingroom': 1,\n",
    "        'Kitchen': 2,\n",
    "        'Dining': 3, \n",
    "        'Corridor': 4,\n",
    "        'Stairs': 5,\n",
    "        'Storeroom': 6,\n",
    "        'Bathroom': 7,\n",
    "        'Balcony': 8,\n",
    "        'Structure': 9,\n",
    "        'Background': 10  # Adjusted the value to match the colors list index\n",
    "    }\n",
    "    legend_handles = [Patch(color=colors[value], label=label) for label, value in legend_labels.items()]\n",
    "    plt.legend(handles=legend_handles, bbox_to_anchor=(-1, 0.0), loc='upper center', ncol=6, fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def infer(model, boundary_image, graph_pyg):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Perform inference\n",
    "        output = model(boundary_image.unsqueeze(0).cuda(), graph_pyg.to('cuda'))\n",
    "        predicted = torch.argmax(output, dim=1)\n",
    "\n",
    "        # Convert tensors to numpy arrays\n",
    "        predicted_np = predicted.cpu().numpy()[0]\n",
    "\n",
    "    return predicted_np\n",
    "\n",
    "\n",
    "def load_sample(graph_path, struct_path):\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # Load struct image\n",
    "    struct_in = np.load(struct_path)\n",
    "    boundary_image = struct_in.astype(np.uint8) \n",
    "    boundary_image = transform(boundary_image)\n",
    "\n",
    "    # Load graph\n",
    "    num_room_types = 4  \n",
    "    num_connection_types = 3 \n",
    "    connection_dic = {'door': 0, 'entrance': 1, 'passage': 2}\n",
    "    \n",
    "    graph_nx = load_pickle(graph_path)\n",
    "    graph_nx.graph['struct'] = struct_in[np.newaxis, ...]\n",
    "    node_features = []\n",
    "    for _, node_data in graph_nx.nodes(data=True):\n",
    "        node_type = node_data['zoning_type']\n",
    "        node_feature = [0]*num_room_types\n",
    "        node_feature[node_type] = 1\n",
    "        node_features.append(node_feature)\n",
    "    \n",
    "    # Add node features if not present\n",
    "    edge_features = []\n",
    "    for _, _, edge_data in graph_nx.edges(data=True):\n",
    "        connection_type = connection_dic[edge_data['connectivity']]\n",
    "        edge_feature = [0]*num_connection_types\n",
    "        edge_feature[connection_type] = 1\n",
    "        edge_features.append(edge_feature)\n",
    "\n",
    "    # Convert to PyG graph\n",
    "    graph_pyg = pyg.utils.from_networkx(graph_nx)\n",
    "    graph_pyg.x = torch.tensor(node_features, dtype=torch.float)  # node features\n",
    "    graph_pyg.edge_attr = torch.tensor(edge_features, dtype=torch.float)  # edge features\n",
    "    \n",
    "    return boundary_image, graph_pyg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aaa6b6b-83e2-43ee-be49-c6c5101c65df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "num_node_features = 4\n",
    "input_nc = 3\n",
    "output_nc = 11\n",
    "\n",
    "model = GraphFloorplanUNet(num_node_features, input_nc, output_nc, features=[64, 128, 256, 512]).cuda()\n",
    "\n",
    "model.load_state_dict(torch.load('/data/iccvw/training_results/unet_v2/model_checkpoint_epoch_490.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1caf48-6537-43f6-9d46-38c5cbc22604",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 1160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a55ed1b6-93fd-4817-9ff2-134e20650d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load sample\n",
    "graph_path = '/data/iccvw/CHALLENGE/dataset_struct_in_aug/val/graph_in/'+str(id)+'.pickle'\n",
    "struct_path = '/data/iccvw/CHALLENGE/dataset_struct_in_aug/val/struct_in/'+str(id)+'.npy'\n",
    "boundary_image, graph_pyg = load_sample(graph_path, struct_path)\n",
    "\n",
    "\n",
    "boundary_image = boundary_image.cuda()\n",
    "graph_pyg = graph_pyg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c779154-a6e9-4b8a-bb42-8623a5a0ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "predicted = infer(model, boundary_image, graph_pyg)\n",
    "\n",
    "# Load ground truth image\n",
    "full_path = '/data/iccvw/CHALLENGE/dataset/val/full_out/'+str(id)+'.npy'\n",
    "gt_image_np = np.load(full_path)[..., 0]\n",
    "\n",
    "raw_boundary_image_path = '/data/iccvw/CHALLENGE/dataset/val/struct_in/'+str(id)+'.npy'\n",
    "boundary_image_np = np.load(raw_boundary_image_path)\n",
    "boundary_img = boundary_image_np[..., 0].astype(np.uint8)\n",
    "\n",
    "# Visualize the result\n",
    "visualize_result(boundary_img, gt_image_np, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c9f425-6999-4338-816b-b603744c397a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch120",
   "language": "python",
   "name": "torch120"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
